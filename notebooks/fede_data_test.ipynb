{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/f/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/f/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/f/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import unidecode\n",
    "from lyricsgenius import Genius\n",
    "import spotipy\n",
    "import spotipy.util as util\n",
    "import text2emotion as te\n",
    "from difflib import SequenceMatcher\n",
    "import nltk\n",
    "import ast\n",
    "import time\n",
    "# nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_path = find_dotenv()\n",
    "load_dotenv(env_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Getting raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence</th>\n",
       "      <th>year</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>artists</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>id</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0594</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.982</td>\n",
       "      <td>['Sergei Rachmaninoff', 'James Levine', 'Berli...</td>\n",
       "      <td>0.279</td>\n",
       "      <td>831667</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0</td>\n",
       "      <td>4BJqT0PrAfrxzMOxytFOIz</td>\n",
       "      <td>0.878</td>\n",
       "      <td>10</td>\n",
       "      <td>0.665</td>\n",
       "      <td>-20.096</td>\n",
       "      <td>1</td>\n",
       "      <td>Piano Concerto No. 3 in D Minor, Op. 30: III. ...</td>\n",
       "      <td>4</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>80.954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9630</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.732</td>\n",
       "      <td>['Dennis Day']</td>\n",
       "      <td>0.819</td>\n",
       "      <td>180533</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0</td>\n",
       "      <td>7xPhfUan2yNtyFG0cUWkt8</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.160</td>\n",
       "      <td>-12.441</td>\n",
       "      <td>1</td>\n",
       "      <td>Clancy Lowered the Boom</td>\n",
       "      <td>5</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.4150</td>\n",
       "      <td>60.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0394</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.961</td>\n",
       "      <td>['KHP Kridhamardawa Karaton Ngayogyakarta Hadi...</td>\n",
       "      <td>0.328</td>\n",
       "      <td>500062</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0</td>\n",
       "      <td>1o6I8BglA6ylDMrIELygv1</td>\n",
       "      <td>0.913</td>\n",
       "      <td>3</td>\n",
       "      <td>0.101</td>\n",
       "      <td>-14.850</td>\n",
       "      <td>1</td>\n",
       "      <td>Gati Bali</td>\n",
       "      <td>5</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>110.339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   valence  year  acousticness  \\\n",
       "0   0.0594  1921         0.982   \n",
       "1   0.9630  1921         0.732   \n",
       "2   0.0394  1921         0.961   \n",
       "\n",
       "                                             artists  danceability  \\\n",
       "0  ['Sergei Rachmaninoff', 'James Levine', 'Berli...         0.279   \n",
       "1                                     ['Dennis Day']         0.819   \n",
       "2  ['KHP Kridhamardawa Karaton Ngayogyakarta Hadi...         0.328   \n",
       "\n",
       "   duration_ms  energy  explicit                      id  instrumentalness  \\\n",
       "0       831667   0.211         0  4BJqT0PrAfrxzMOxytFOIz             0.878   \n",
       "1       180533   0.341         0  7xPhfUan2yNtyFG0cUWkt8             0.000   \n",
       "2       500062   0.166         0  1o6I8BglA6ylDMrIELygv1             0.913   \n",
       "\n",
       "   key  liveness  loudness  mode  \\\n",
       "0   10     0.665   -20.096     1   \n",
       "1    7     0.160   -12.441     1   \n",
       "2    3     0.101   -14.850     1   \n",
       "\n",
       "                                                name  popularity release_date  \\\n",
       "0  Piano Concerto No. 3 in D Minor, Op. 30: III. ...           4         1921   \n",
       "1                            Clancy Lowered the Boom           5         1921   \n",
       "2                                          Gati Bali           5         1921   \n",
       "\n",
       "   speechiness    tempo  \n",
       "0       0.0366   80.954  \n",
       "1       0.4150   60.936  \n",
       "2       0.0339  110.339  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the dataset into a dataframe\n",
    "data = pd.read_csv('../raw_data/data.csv')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sample to work with a smaller dataset throughout development\n",
    "data_sample = data.sample(100, ignore_index=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1) Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean strings\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Removes symbols, accents and uppercases from text.\n",
    "    \"\"\"\n",
    "    text = text.replace(\"[\",'')\\\n",
    "        .replace(\"]\",'')\\\n",
    "        .replace(\"'\",'')\\\n",
    "        .replace(\",\",'')\\\n",
    "        .replace(\":\",'')\\\n",
    "        .replace(\")\",'')\\\n",
    "        .replace(\"(\",'')\\\n",
    "        .replace(\".\",'')\\\n",
    "        .replace('\"','')\\\n",
    "        .replace('/','')\\\n",
    "        .replace(\"\\\\\",'')\\\n",
    "        .replace(\"(?)\",'')\\\n",
    "        .replace(\"-\",'')\n",
    "        \n",
    "    return unidecode.unidecode(text.lower())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2) get_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lyrics\n",
    "def get_lyrics(artist, song_title, genius):\n",
    "    \"\"\"\n",
    "    Returns lyrics from Genius API.\n",
    "    \"\"\"\n",
    "    # cleanup the inputs\n",
    "    artist = clean_text(artist)\n",
    "    song_title = clean_text(song_title)\n",
    "    \n",
    "    # call the API to search for the song\n",
    "    song = genius.search_song(title=song_title, artist=artist)\n",
    "\n",
    "    if song != None:\n",
    "        # get song name from the API response to compare similarity\n",
    "        api_response = unidecode.unidecode(song.to_dict()['full_title'].replace('\\xa0', ' ').replace('\\u200b', ' ').lower())\n",
    "        api_response = api_response.split(' by ')\n",
    "        # check similarity\n",
    "        song_similar = similar(api_response[0], song_title)\n",
    "        # artist_similar = similar(api_response[1], artist)\n",
    "\n",
    "        if song_similar >= 0.9:\n",
    "            # all lyrics responses come with the song's title and 'Lyrics' str\n",
    "            # so we count how many characters should be removed in order \n",
    "            # to delete any extra text\n",
    "            characters_to_remove = len(song.to_dict()['title'] + ' Lyrics')   \n",
    "            \n",
    "            # get lyrics from API\n",
    "            lyrics = genius.lyrics(song.to_dict()['id'])[characters_to_remove:-5].replace('\\n', ' ').strip()\n",
    "\n",
    "        else:\n",
    "            lyrics = None\n",
    "    \n",
    "    else:\n",
    "        lyrics = None\n",
    "    \n",
    "    return lyrics\n",
    "\n",
    "\n",
    "# we need to check similarity between the input of the API call and the response\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_lyrics = get_lyrics(data_sample['artists'][7], data_sample['name'][7])\n",
    "# test_lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3) get_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sentiments\n",
    "def get_sentiments(lyrics):\n",
    "    \"\"\"\n",
    "    Get sentiments from lyrics using VADER.\n",
    "    \"\"\"\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    sentiments = sid.polarity_scores(clean_text(lyrics))\n",
    "    \n",
    "    return sentiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_sentiments = get_sentiments(test_lyrics)\n",
    "# test_sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4) get_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get emotions\n",
    "def get_emotions(lyrics):\n",
    "    \"\"\"\n",
    "    Get emotions from lyrics using text2emotion.\n",
    "    \"\"\"\n",
    "    emotions = te.get_emotion(clean_text(lyrics))\n",
    "    emotions = {key.lower(): value for key, value in emotions.items()}   \n",
    "     \n",
    "    return emotions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_emotions = get_emotions(test_lyrics)\n",
    "# test_emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Loading credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get credentials for Genius API\n",
    "genius_token = os.environ.get('LYRICSGENIUS_ACCESS_TOKEN')\n",
    "\n",
    "# instantiate the Genius class with some useful hyperparameters\n",
    "genius = Genius(genius_token, \n",
    "                timeout=220, \n",
    "                remove_section_headers=True,\n",
    "                skip_non_songs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Getting full DataFrame ❗️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❗️ Choose **one** option and remove the other: ❗️\\\n",
    "\\\n",
    "**A)** Regular Processing\\\n",
    "**B)** Parallel Multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Regular Processing ❌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# create df containing lyrics, sentiments and emotions\\ndef get_full_dataframe(df, genius):\\n    \"\"\"\\n    Returns a DataFrame adding lyrics, sentiments and emotions.\\n    \"\"\"\\n    # add lyrics to df\\n    df[\\'lyrics\\'] = \\'\\'\\n    df[\\'sentiments\\'] = \\'\\'\\n    df[\\'emotions\\'] = \\'\\'\\n    \\n    for index in range(len(df)):\\n        #start = time.time()\\n        lyrics = get_lyrics(df[\\'artists\\'][index], df[\\'name\\'][index], genius)\\n        #end = time.time()\\n        #print(f\"get_lyrics {end - start} s\")\\n        \\n        #start = time.time()\\n        df[\\'lyrics\\'][index] = df[\\'lyrics\\'][index].replace(\\'\\', str(lyrics))\\n        #end = time.time()\\n        #print(f\"saving lyrics {end - start} s\")\\n\\n        if lyrics != \\'None\\':\\n            #start = time.time()\\n            sentiments = get_sentiments(lyrics)         \\n            df[\\'sentiments\\'][index] = df[\\'sentiments\\'][index].replace(\\'\\', str(sentiments))\\n            #end = time.time()\\n            #print(f\"get_sentiments {end - start} s\")\\n\\n            #start = time.time()\\n            emotions = get_emotions(lyrics)         \\n            df[\\'emotions\\'][index] = df[\\'emotions\\'][index].replace(\\'\\', str(emotions))\\n            #end = time.time()\\n            #print(f\"get_emotions {end - start} s\")\\n            \\n        else:\\n            df[\\'sentiments\\'][index] = df[\\'sentiments\\'][index].replace(\\'\\', \\'None\\')\\n            df[\\'emotions\\'][index] = df[\\'emotions\\'][index].replace(\\'\\', \\'None\\')\\n \\n    # transform sentiments and emotions from string to dict    \\n    df[\\'sentiments\\'] = df[\\'sentiments\\'].apply(lambda x: ast.literal_eval(x))\\n    df[\\'emotions\\'] = df[\\'emotions\\'].apply(lambda x: ast.literal_eval(x))\\n\\n    # create a dataframe with each sentiment in separate columns\\n    sentiments_df = df[\\'sentiments\\'].apply(pd.Series)\\n    sentiments_df = sentiments_df.fillna(\\'None\\')\\n    df = pd.concat([df, sentiments_df], axis=1)\\n    \\n\\n    # create a dataframe with each emotion in separate columns\\n    emotions_df = df[\\'emotions\\'].apply(pd.Series)\\n    emotions_df = emotions_df.fillna(\\'None\\')\\n    df = pd.concat([df, emotions_df], axis=1)\\n    \\n    return df\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# create df containing lyrics, sentiments and emotions\n",
    "def get_full_dataframe(df, genius):\n",
    "    \"\"\"\n",
    "    Returns a DataFrame adding lyrics, sentiments and emotions.\n",
    "    \"\"\"\n",
    "    # add lyrics to df\n",
    "    df['lyrics'] = ''\n",
    "    df['sentiments'] = ''\n",
    "    df['emotions'] = ''\n",
    "    \n",
    "    for index in range(len(df)):\n",
    "        #start = time.time()\n",
    "        lyrics = get_lyrics(df['artists'][index], df['name'][index], genius)\n",
    "        #end = time.time()\n",
    "        #print(f\"get_lyrics {end - start} s\")\n",
    "        \n",
    "        #start = time.time()\n",
    "        df['lyrics'][index] = df['lyrics'][index].replace('', str(lyrics))\n",
    "        #end = time.time()\n",
    "        #print(f\"saving lyrics {end - start} s\")\n",
    "\n",
    "        if lyrics != 'None':\n",
    "            #start = time.time()\n",
    "            sentiments = get_sentiments(lyrics)         \n",
    "            df['sentiments'][index] = df['sentiments'][index].replace('', str(sentiments))\n",
    "            #end = time.time()\n",
    "            #print(f\"get_sentiments {end - start} s\")\n",
    "\n",
    "            #start = time.time()\n",
    "            emotions = get_emotions(lyrics)         \n",
    "            df['emotions'][index] = df['emotions'][index].replace('', str(emotions))\n",
    "            #end = time.time()\n",
    "            #print(f\"get_emotions {end - start} s\")\n",
    "            \n",
    "        else:\n",
    "            df['sentiments'][index] = df['sentiments'][index].replace('', 'None')\n",
    "            df['emotions'][index] = df['emotions'][index].replace('', 'None')\n",
    " \n",
    "    # transform sentiments and emotions from string to dict    \n",
    "    df['sentiments'] = df['sentiments'].apply(lambda x: ast.literal_eval(x))\n",
    "    df['emotions'] = df['emotions'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "    # create a dataframe with each sentiment in separate columns\n",
    "    sentiments_df = df['sentiments'].apply(pd.Series)\n",
    "    sentiments_df = sentiments_df.fillna('None')\n",
    "    df = pd.concat([df, sentiments_df], axis=1)\n",
    "    \n",
    "\n",
    "    # create a dataframe with each emotion in separate columns\n",
    "    emotions_df = df['emotions'].apply(pd.Series)\n",
    "    emotions_df = emotions_df.fillna('None')\n",
    "    df = pd.concat([df, emotions_df], axis=1)\n",
    "    \n",
    "    return df\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get full dataframe\n",
    "#test_df = get_full_dataframe(data_sample, genius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Parallel Multiprocessing ✅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_song(artist, song_title, genius):\n",
    "\n",
    "    lyrics = get_lyrics(artist, song_title, genius)\n",
    "\n",
    "    if lyrics != None:\n",
    "        sentiments = get_sentiments(lyrics)\n",
    "        emotions = get_emotions(lyrics)         \n",
    "\n",
    "    else:\n",
    "        sentiments = None\n",
    "        emotions = None\n",
    "    \n",
    "    return lyrics, sentiments, emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df containing lyrics, sentiments and emotions\n",
    "def get_full_dataframe_parallel(df, genius):\n",
    "    \"\"\"\n",
    "    Returns a DataFrame adding lyrics, sentiments and emotions.\n",
    "    \"\"\"\n",
    "    full_songs = Parallel(n_jobs=os.cpu_count())\\\n",
    "        (delayed(get_full_song)(artist, song_title, genius)\\\n",
    "        for artist, song_title in zip(df['artists'], df['name']))\n",
    "    \n",
    "    full_songs = np.array(full_songs)\n",
    "    \n",
    "    df['lyrics'], df['sentiments'], df['emotions'] = full_songs[:,0], full_songs[:,1], full_songs[:,2]\n",
    "\n",
    "    # create a dataframe with each sentiment in separate columns\n",
    "    sentiments_df = df['sentiments'].apply(pd.Series)\n",
    "    sentiments_df = sentiments_df.fillna('None')\n",
    "    df = pd.concat([df, sentiments_df], axis=1)\n",
    "    \n",
    "    # create a dataframe with each emotion in separate columns\n",
    "    emotions_df = df['emotions'].apply(pd.Series)\n",
    "    emotions_df = emotions_df.fillna('None')\n",
    "    df = pd.concat([df, emotions_df], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/f/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/f/nltk_data...\n",
      "[nltk_data] Downloading package stopwords to /Users/f/nltk_data...\n",
      "[nltk_data] Downloading package stopwords to /Users/f/nltk_data...\n",
      "[nltk_data] Downloading package stopwords to /Users/f/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/f/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/f/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/f/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/f/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/f/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/f/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/f/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for \"raised on it\" by sam hunt...\n",
      "Searching for \"drifter  2015 remaster\" by iron maiden...\n",
      "Searching for \"99 problems\" by jayz...\n",
      "Searching for \"close your eyes\" by parmalee...\n",
      "No results found for: 'drifter  2015 remaster iron maiden'\n",
      "Searching for \"soultana maurofora\" by markos vamvakaris apostolos xatzixristos...\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "No results found for: 'soultana maurofora markos vamvakaris apostolos xatzixristos'\n",
      "Searching for \"just because\" by frankie yankovic...\n",
      "No results found for: 'just because frankie yankovic'\n",
      "Searching for \"a girl in the night\" by ray price...\n",
      "Done.\n",
      "Searching for \"look what youve done\" by drake...\n",
      "Done.\n",
      "Searching for \"wild for the night feat skrillex & birdy nam nam\" by a$ap rocky skrillex birdy nam nam lord flacko...\n",
      "Searching for \"painkiller\" by ruel...\n",
      "Done.\n",
      "Searching for \"available\" by frank sinatra...\n",
      "Done.\n",
      "Done.\n",
      "Searching for \"voices\" by disturbed...\n",
      "Done.\n",
      "Searching for \"so icy feat young jeezy\" by gucci mane jeezy...\n",
      "Searching for \"gone too soon\" by daughtry...\n",
      "Done.\n",
      "Searching for \"if i told you this was killing me would you stop?\" by the juliana theory...\n",
      "Done.\n",
      "Done.\n",
      "Searching for \"naima\" by john coltrane...\n",
      "Specified song does not contain lyrics. Rejecting.\n",
      "Searching for \"will i\" by aaron lohr wayne wilcox cast of the motion picture rent...\n",
      "Done.\n",
      "Searching for \"wholy holy  mono single version\" by marvin gaye...\n",
      "Done.\n",
      "Searching for \"wrong feat lil mosey\" by the kid laroi lil mosey...\n",
      "Searching for \"hermit songs op 29 the praises of god\" by samuel barber leontyne price...\n",
      "Done.\n",
      "Searching for \"the bells of dublinchristmas eve\" by the chieftains...\n",
      "No results found for: 'hermit songs op 29 the praises of god samuel barber leontyne price'\n",
      "Searching for \"bota y tambo\" by sabor kolombia...\n",
      "Searching for \"the invasion of kushana\" by joe hisaishi...\n",
      "Specified song does not contain lyrics. Rejecting.\n",
      "Searching for \"brackets\" by j cole...\n",
      "No results found for: 'bota y tambo sabor kolombia'\n",
      "Searching for \"a tree grows in brooklyn overture\" by arthur schwartz a tree grows in brooklyn orchestra jay blackton...\n",
      "Done.\n",
      "Searching for \"exactly like you\" by oscar peterson trio herb ellis...\n",
      "No results found for: 'a tree grows in brooklyn overture arthur schwartz a tree grows in brooklyn orchestra jay blackton'\n",
      "Searching for \"nickel sized hail feat colt ford\" by sunny ledfurd colt ford...\n",
      "Done.\n",
      "Searching for \"just another day in paradise\" by bertie higgins...\n",
      "No results found for: 'exactly like you oscar peterson trio herb ellis'\n",
      "Searching for \"senorita cantinera\" by antonio aguilar...\n",
      "Done.\n",
      "Searching for \"no heart\" by ynw melly...\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Searching for \"i let a song go out of my heart\" by don shirley...\n",
      "Done.\n",
      "Searching for \"devoted to you  remastered\" by the beach boys...\n",
      "Done.\n",
      "Searching for \"gangs in the street  remastered 2006\" by loverboy...\n",
      "No results found for: 'gangs in the street  remastered 2006 loverboy'\n",
      "Searching for \"power of love\" by deeelite...\n",
      "Done.\n",
      "Searching for \"blood on the floor\" by fleetwood mac...\n",
      "Searching for \"out on the tiles\" by led zeppelin...\n",
      "Done.\n",
      "Done.\n",
      "Searching for \"making love ukelele style\" by paul weirick charles hayes the chordettes...\n",
      "No results found for: 'making love ukelele style paul weirick charles hayes the chordettes'\n",
      "Searching for \"le nozze di figaro k 492 act iv scene 8 tutto e disposto ... aprite un po quelgli occhi figaro\" by wolfgang amadeus mozart glyndebourne festival orchestra sesto bruscantini vittorio gui...\n",
      "Searching for \"where i belong\" by building 429...\n",
      "No results found for: 'le nozze di figaro k 492 act iv scene 8 tutto e disposto ... aprite un po quelgli occhi figaro wolfgang amadeus mozart glyndebourne festival orchestra sesto bruscantini vittorio gui'\n",
      "Searching for \"flor de ceibo  remasterizado\" by francisco canaro charlo...\n",
      "No results found for: 'flor de ceibo  remasterizado francisco canaro charlo'\n",
      "Searching for \"silent night\" by justin bieber...\n",
      "Done.\n",
      "Searching for \"arrive derce roma\" by arthur lyman...\n",
      "Done.\n",
      "No results found for: 'arrive derce roma arthur lyman'\n",
      "Searching for \"say it over feat cautious clay\" by ruel cautious clay...\n",
      "Done.\n",
      "Searching for \"asi te quiero\" by joan sebastian...\n",
      "Searching for \"polonaise in aflat major op 53 heroic\" by frederic chopin vladimir horowitz...\n",
      "Done.\n",
      "No results found for: 'polonaise in aflat major op 53 heroic frederic chopin vladimir horowitz'\n",
      "Searching for \"little girl\" by ritchie valens...\n",
      "Searching for \"viet nam\" by minutemen...\n",
      "Done.\n",
      "Searching for \"take good care of my baby\" by bobby vee...\n",
      "Done.\n",
      "Searching for \"where the boys go  remastered\" by the rolling stones...\n",
      "Searching for \"you belong to my heart solamente una vez  from the three caballeros\" by dora luz...\n",
      "Done.\n",
      "No results found for: 'you belong to my heart solamente una vez  from the three caballeros dora luz'\n",
      "Searching for \"pussy talk feat quavo lil wayne & jack harlow remix\" by city girls quavo lil wayne jack harlow...\n",
      "Done.\n",
      "Searching for \"margaritaville\" by jimmy buffett...\n",
      "Done.\n",
      "Searching for \"your love\" by the outfield...\n",
      "Done.\n",
      "Searching for \"ding dong  take 1  take 2\" by lester young...\n",
      "Done.\n",
      "Searching for \"cant we just sit down and talk it over\" by donna summer...\n",
      "Done.\n",
      "Searching for \"when day is done\" by coleman hawkins...\n",
      "Done.\n",
      "Specified song does not contain lyrics. Rejecting.\n",
      "Searching for \"the game has changed\" by daft punk...\n",
      "Specified song does not contain lyrics. Rejecting.\n",
      "Searching for \"my fairy king  remastered 2011\" by queen...\n",
      "Done.\n",
      "Searching for \"somebody kill me\" by adam sandler...\n",
      "Searching for \"walters walk  rough mix\" by led zeppelin...\n",
      "Done.\n",
      "Searching for \"soja soja soja ri\" by gauhar sultana vasanti...\n",
      "No results found for: 'soja soja soja ri gauhar sultana vasanti'\n",
      "Searching for \"paper mountain man\" by linda perhacs...\n",
      "Done.\n",
      "Searching for \"please love me forever\" by bobby vinton...\n",
      "Done.\n",
      "Searching for \"amanaz\" by amanaz...\n",
      "Specified song does not contain lyrics. Rejecting.\n",
      "Searching for \"atras da porta\" by elis regina...\n",
      "Searching for \"born to be blue\" by helen merrill...\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Searching for \"bang!\" by ajr...\n",
      "Done.\n",
      "Searching for \"temptation of the renaissance air  variations  dance\" by stepan rak vladimir mikulka...\n",
      "No results found for: 'temptation of the renaissance air  variations  dance stepan rak vladimir mikulka'\n",
      "Searching for \"pete khele pite soi\" by gramophone club...\n",
      "No results found for: 'pete khele pite soi gramophone club'\n",
      "Searching for \"success\" by jayz nas...\n",
      "Searching for \"burial\" by peter tosh...\n",
      "Searching for \"dont pass me by bonus track\" by ey harburg burton lane...\n",
      "No results found for: 'dont pass me by bonus track ey harburg burton lane'\n",
      "Searching for \"something to live for\" by nina simone...\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Searching for \"away in a manger\" by percy faith & his orchestra...\n",
      "Done.\n",
      "Searching for \"from this day on  outtake\" by gene kelly carol richards...\n",
      "No results found for: 'from this day on  outtake gene kelly carol richards'\n",
      "Searching for \"desh ki pur kaif\" by roshan ara begum...\n",
      "No results found for: 'desh ki pur kaif roshan ara begum'\n",
      "Searching for \"hard on yourself\" by charlie puth blackbear...\n",
      "Searching for \"greenfields\" by the brothers four...\n",
      "Done.\n",
      "Done.\n",
      "Searching for \"behind the gardens behind the wall under the tree\" by andreas vollenweider walter keiser pedro haldemann...\n",
      "No results found for: 'behind the gardens behind the wall under the tree andreas vollenweider walter keiser pedro haldemann'\n",
      "Searching for \"fuck you bitch\" by wheeler walker jr...\n",
      "Done.\n",
      "Searching for \"lockjaw feat kodak black\" by french montana kodak black...\n",
      "Searching for \"like jesus does\" by eric church...\n",
      "Done.\n",
      "Searching for \"by myself\" by jerry lewis...\n",
      "Done.\n",
      "Done.\n",
      "Searching for \"ae kafile wale mera paigham liye ja\" by zeenat begum qadir faridi...\n",
      "Searching for \"silbando  remasterizado\" by francisco canaro azucena maizani...\n",
      "No results found for: 'ae kafile wale mera paigham liye ja zeenat begum qadir faridi'\n",
      "Searching for \"freaks\" by surf curse...\n",
      "No results found for: 'silbando  remasterizado francisco canaro azucena maizani'\n",
      "Searching for \"honey in the honeycomb\" by ethel waters...\n",
      "Done.\n",
      "Searching for \"i wish feat ti\" by cher lloyd ti...\n",
      "Done.\n",
      "Done.\n",
      "Searching for \"for all we know\" by ahmad jamal...\n",
      "Done.\n",
      "Searching for \"burn  radio mix\" by usher...\n",
      "Searching for \"main title\" by charlie chaplin...\n",
      "Searching for \"pain is so close to pleasure\" by queen...\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Searching for \"peddler man ten i loved\" by dean martin...\n",
      "Searching for \"radio\" by lana del rey...\n",
      "Done.\n",
      "Done.\n",
      "Searching for \"ya men ykolak\" by layla mourad...\n",
      "Searching for \"bura kisko manoon bhala kisko\" by pearu qawal...\n",
      "No results found for: 'ya men ykolak layla mourad'\n",
      "Searching for \"hablar de ti\" by duelo...\n",
      "No results found for: 'bura kisko manoon bhala kisko pearu qawal'\n",
      "Searching for \"community property\" by steel panther...\n",
      "Done.\n",
      "Done.\n",
      "Searching for \"cherokee\" by stephen stills...\n",
      "Searching for \"dance the night away  2015 remaster\" by van halen...\n",
      "Done.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "test_result = get_full_dataframe_parallel(data_sample, genius)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_full_dataframe_parallel for 100 samples: 1.4295635024706523 m\n"
     ]
    }
   ],
   "source": [
    "print(f\"get_full_dataframe_parallel for {len(test_result)} samples: {(end - start)/60} m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence</th>\n",
       "      <th>year</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>artists</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>id</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>...</th>\n",
       "      <th>emotions</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>happy</th>\n",
       "      <th>angry</th>\n",
       "      <th>surprise</th>\n",
       "      <th>sad</th>\n",
       "      <th>fear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.817</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.015800</td>\n",
       "      <td>['Parmalee']</td>\n",
       "      <td>0.551</td>\n",
       "      <td>214933</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0</td>\n",
       "      <td>3Bdqlr7jQLNhITAgcBGQBG</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>{'happy': 0.24, 'angry': 0.07, 'surprise': 0.2...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.9939</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.548</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.006610</td>\n",
       "      <td>['JAY-Z']</td>\n",
       "      <td>0.494</td>\n",
       "      <td>234627</td>\n",
       "      <td>0.887</td>\n",
       "      <td>1</td>\n",
       "      <td>7sLpSWxQazJzDVG6YGzlVs</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>{'happy': 0.05, 'angry': 0.13, 'surprise': 0.2...</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.098</td>\n",
       "      <td>-0.9995</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.732</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.047700</td>\n",
       "      <td>['Sam Hunt']</td>\n",
       "      <td>0.590</td>\n",
       "      <td>235507</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0</td>\n",
       "      <td>3BuPop8SzLG2Q88TJcFAjp</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>{'happy': 0.09, 'angry': 0.13, 'surprise': 0.1...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.9786</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.475</td>\n",
       "      <td>1981</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>['Iron Maiden']</td>\n",
       "      <td>0.340</td>\n",
       "      <td>288947</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0</td>\n",
       "      <td>7EvjTEzuv7TWaIaWY63sWV</td>\n",
       "      <td>0.0928</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.550</td>\n",
       "      <td>1930</td>\n",
       "      <td>0.994000</td>\n",
       "      <td>['Markos Vamvakaris', 'Apostolos Xatzixristos']</td>\n",
       "      <td>0.410</td>\n",
       "      <td>197653</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0</td>\n",
       "      <td>38PozVGXXoeO8dTEVzy74Y</td>\n",
       "      <td>0.9010</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   valence  year  acousticness  \\\n",
       "0    0.817  2013      0.015800   \n",
       "1    0.548  2003      0.006610   \n",
       "2    0.732  2014      0.047700   \n",
       "3    0.475  1981      0.000473   \n",
       "4    0.550  1930      0.994000   \n",
       "\n",
       "                                           artists  danceability  duration_ms  \\\n",
       "0                                     ['Parmalee']         0.551       214933   \n",
       "1                                        ['JAY-Z']         0.494       234627   \n",
       "2                                     ['Sam Hunt']         0.590       235507   \n",
       "3                                  ['Iron Maiden']         0.340       288947   \n",
       "4  ['Markos Vamvakaris', 'Apostolos Xatzixristos']         0.410       197653   \n",
       "\n",
       "   energy  explicit                      id  instrumentalness  ...  \\\n",
       "0   0.863         0  3Bdqlr7jQLNhITAgcBGQBG            0.0000  ...   \n",
       "1   0.887         1  7sLpSWxQazJzDVG6YGzlVs            0.0000  ...   \n",
       "2   0.940         0  3BuPop8SzLG2Q88TJcFAjp            0.0000  ...   \n",
       "3   0.974         0  7EvjTEzuv7TWaIaWY63sWV            0.0928  ...   \n",
       "4   0.169         0  38PozVGXXoeO8dTEVzy74Y            0.9010  ...   \n",
       "\n",
       "                                            emotions    neg    neu    pos  \\\n",
       "0  {'happy': 0.24, 'angry': 0.07, 'surprise': 0.2...    0.0  0.854  0.146   \n",
       "1  {'happy': 0.05, 'angry': 0.13, 'surprise': 0.2...  0.269  0.633  0.098   \n",
       "2  {'happy': 0.09, 'angry': 0.13, 'surprise': 0.1...   0.06  0.824  0.116   \n",
       "3                                               None   None   None   None   \n",
       "4                                               None   None   None   None   \n",
       "\n",
       "  compound  happy angry  surprise   sad  fear  \n",
       "0   0.9939   0.24  0.07      0.28  0.34  0.07  \n",
       "1  -0.9995   0.05  0.13      0.23  0.14  0.45  \n",
       "2   0.9786   0.09  0.13      0.15  0.31  0.32  \n",
       "3     None   None  None      None  None  None  \n",
       "4     None   None  None      None  None  None  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Saving DataFrame to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7k/g6_9j05d4qg33cskxqfft6dh0000gn/T/ipykernel_3250/2685386131.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# save dataframe to csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../processed_data/processed_test_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_df' is not defined"
     ]
    }
   ],
   "source": [
    "# save dataframe to csv\n",
    "test_df.to_csv('../processed_data/processed_test_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('lewagon')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7c7d6478cee8e23e85426c90b6378b600ffc0f1f14c388e216ad8a5523bab00c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
